{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e46bc4-f64f-49df-a53c-ce9545f28ab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "\n",
    "# Function to download OHLCV data\n",
    "def download_ohlcv_data(symbols, start_date, end_date, output_folder):\n",
    "    for symbol in symbols:\n",
    "        try:\n",
    "            nse_symbol = symbol.strip() + \".NS\"\n",
    "            print(f\"Downloading data for {nse_symbol}...\")\n",
    "            \n",
    "            data = yf.download(nse_symbol, start=start_date, end=end_date, progress=False, multi_level_index=False)\n",
    "\n",
    "            if not data.empty:\n",
    "                file_path = f\"{output_folder}/{symbol}_ohlcv.csv\"\n",
    "                data.to_csv(file_path)\n",
    "                print(f\"Data saved for {symbol} at {file_path}\")\n",
    "            else:\n",
    "                print(f\"No data found for {symbol}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading data for {symbol}: {e}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"nse_symbols.csv\"  \n",
    "    output_folder = \"ohlcv_data\"   \n",
    "\n",
    "    try:\n",
    "        symbols_df = pd.read_csv(input_csv)\n",
    "        symbols = symbols_df['Symbol'].tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the input CSV file: {e}\")\n",
    "        exit()\n",
    "\n",
    "    end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "    start_date = (datetime.today() - timedelta(days=10*365)).strftime('%Y-%m-%d')\n",
    "\n",
    "    print(f\"Fetching data from {start_date} to {end_date}...\")\n",
    "\n",
    "    import os\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    download_ohlcv_data(symbols, start_date, end_date, output_folder)\n",
    "\n",
    "    print(\"Process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a489ec94-8cf4-47f9-8ac1-7f82058c6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data sanity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def sanity_check(ticker_name):\n",
    "    file_name = f\"ohlcv_data/{ticker_name}_ohlcv.csv\"\n",
    "    df = pd.read_csv(file_name)\n",
    "\n",
    "    print(f\"\\nProcessing: {ticker_name}\")\n",
    "\n",
    "    # checking if columns are present\n",
    "    required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Missing columns: {missing_cols}\")\n",
    "        return\n",
    "\n",
    "    # forward fill\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(f\"Missing Values:\\n{missing_values}\")\n",
    "    df.ffill(inplace=True, limit=1)\n",
    "\n",
    "    # checking for duplicates\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    print(f\"Duplicate Rows: {duplicate_count}\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # checking for negative and zeroes\n",
    "    invalid_rows = df[(df[required_cols] <= 0).any(axis=1)]\n",
    "    print(f\"Invalid (Zero/Negative) Values: {len(invalid_rows)} rows\")\n",
    "\n",
    "    for col in required_cols:\n",
    "        df[col] = df[col].replace(0, np.nan).ffill(limit=1)\n",
    "        df[col] = df[col].where(df[col] > 0, np.nan).ffill(limit=1)\n",
    "\n",
    "    # sorting by date Date\n",
    "    if 'Date' in df.columns:\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df.sort_values('Date', inplace=True)\n",
    "        print(f\"Date Range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "\n",
    "    # Printing Correlation Matrix\n",
    "    print(f\"Correlation Matrix for {ticker_name}:\\n{df[required_cols].corr()}\")\n",
    "\n",
    "    # Save Cleaned Data\n",
    "    cleaned_file = f\"cleaned_data/{ticker_name}_cleaned.csv\"\n",
    "    df.to_csv(cleaned_file, index=False)\n",
    "    print(f\"Cleaned data saved: {cleaned_file}\")\n",
    "\n",
    "\n",
    "input_csv = \"nse_symbols.csv\"\n",
    "symbols_df = pd.read_csv(input_csv)\n",
    "symbols = symbols_df['Symbol'].tolist()\n",
    "\n",
    "for symbol in symbols:\n",
    "    sanity_check(symbol)\n",
    "\n",
    "print(\"\\nData Sanity Check Completed for All Symbols!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0d111-f742-4b8b-8d01-86f4e2d3e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "import yfinance as yf\n",
    "import talib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_indicators(ticker_name):\n",
    "    file_name = \"cleaned_data/\" + ticker_name + \"_cleaned.csv\"\n",
    "    df = pd.read_csv(file_name)\n",
    "\n",
    "    Close = df['Close'].astype(float).to_numpy()\n",
    "    Open = df['Open'].astype(float).to_numpy()\n",
    "    High = df['High'].astype(float).to_numpy()\n",
    "    Low = df['Low'].astype(float).to_numpy()\n",
    "    Volume = df['Volume'].astype(float).to_numpy()\n",
    "\n",
    "    \n",
    "    #Volume based indicators\n",
    "    AD = talib.AD(High, Low, Close, Volume)\n",
    "    AD_trend = np.diff(AD, prepend=np.nan)\n",
    "    AD_Crossover = np.where((AD > 0) & (np.roll(AD, 1) <= 0), 1,\n",
    "                                  np.where((AD < 0) & (np.roll(AD, 1) >= 0), -1, 0))\n",
    "    ADOSC = talib.ADOSC(High, Low, Close, Volume, fastperiod=3, slowperiod=10)\n",
    "    ADOSC_trend = np.diff(ADOSC, prepend=np.nan)\n",
    "    ADOSC_Crossover = np.where((ADOSC > 0) & (np.roll(ADOSC,1) <= 0), 1,\n",
    "                                     np.where((ADOSC < 0) & (np.roll(ADOSC,1) >= 0), -1, 0))\n",
    "    #directional movement indicators\n",
    "    ADX = talib.ADX(High, Low, Close, timeperiod=5)\n",
    "    ADX_trend = np.diff(ADX, prepend=np.nan)\n",
    "    PLUS_DI=talib.PLUS_DI(High, Low, Close, timeperiod=5)\n",
    "    MINUS_DI=talib.MINUS_DI(High, Low, Close, timeperiod=5)\n",
    "    DI_Crossover = np.where((PLUS_DI > MINUS_DI) & (np.roll(PLUS_DI, 1) <= np.roll(MINUS_DI, 1))), 1, np.where((PLUS_DI < MINUS_DI) & (np.roll(PLUS_DI, 1) >= np.roll(MINUS_DI, 1)), -1, 0)\n",
    "    ADXR = talib.ADXR(High, Low, Close, timeperiod=5)\n",
    "    ADXR_trend = np.diff(ADXR, prepend=np.nan)\n",
    "    MINUS_DM=talib.MINUS_DM(High, Low, timeperiod=5)\n",
    "    PLUS_DM=talib.PLUS_DM(High, Low, timeperiod=5)\n",
    "    DM_Crossover = np.where((PLUS_DM > MINUS_DM) & (np.roll(PLUS_DM, 1) <= np.roll(MINUS_DM, 1)), 1,\n",
    "                        np.where((PLUS_DM < MINUS_DM) & (np.roll(PLUS_DM, 1) >= np.roll(MINUS_DM, 1)), -1, 0))\n",
    "    \n",
    "    #momentum indicators\n",
    "    APO=talib.APO(Close, fastperiod=5, slowperiod=10, matype=0)\n",
    "    APO_trend = np.diff(APO, prepend=np.nan)\n",
    "    APO_Crossover = np.where((APO > 0) & (np.roll(APO,1) <= 0), 1, np.where((APO < 0) & (np.roll(APO,1) >= 0), -1, 0))\n",
    "    AROON_UP, AROON_DOWN =talib.AROON(High, Low, timeperiod=5)\n",
    "    AROONOSC=talib.AROONOSC(High, Low, timeperiod=5)\n",
    "    AROON_Crossover = np.where((AROON_UP > AROON_DOWN) & (np.roll(AROON_UP,1) <= np.roll(AROON_DOWN,1)), 1,\n",
    "                                     np.where((AROON_UP < AROON_DOWN) & (np.roll(AROON_UP,1) >= np.roll(AROON_DOWN,1)), -1, 0))\n",
    "    MOM=talib.MOM(Close, timeperiod=5)\n",
    "    MOM_trend = np.diff(MOM, prepend=np.nan)\n",
    "    MOM_Crossover = np.where((MOM > 0) & (np.roll(MOM,1) <= 0), 1,\n",
    "                                np.where((MOM < 0) & (np.roll(MOM,1) >= 0), -1, 0)).tolist()\n",
    "    \n",
    "    #volatility indicators\n",
    "    ATR=talib.ATR(High, Low, Close, timeperiod=5)\n",
    "    ATR_trend = np.diff(ATR, prepend=np.nan)\n",
    "    ATR_breakout = np.where(np.diff(Close) > ATR[1:], 1, np.where(np.diff(Close) < -ATR[1:], -1, 0))\n",
    "    NATR=talib.NATR(High, Low, Close, timeperiod=5)\n",
    "    NATR_trend = np.diff(NATR, prepend=np.nan)\n",
    "    High_Volatility = np.where(NATR > 20, 1, np.where(NATR < 5, -1, 0))\n",
    "    TRANGE=talib.TRANGE(High, Low, Close)\n",
    "    TRANGE_trend = np.diff(TRANGE, prepend=np.nan)\n",
    "    Volatility_Spike = np.where(TRANGE > np.convolve(TRANGE, np.ones(5) / 5, mode='same') * 1.5, 1, 0)\n",
    "\n",
    "\n",
    "    #price indicators\n",
    "    AVGPRICE=talib.AVGPRICE(Open, High, Low, Close)\n",
    "    Price_Deviation = Close - AVGPRICE\n",
    "    AVGPRICE_trend = np.diff(AVGPRICE, prepend = np.nan)\n",
    "    AVGPRICE_Crossover = np.where(Close > AVGPRICE, 1, np.where(Close < AVGPRICE, -1, 0))\n",
    "    BETA=talib.BETA(High, Low, timeperiod=5)\n",
    "    BETA_trend = np.diff(BETA, prepend=np.nan)\n",
    "    High_Beta_Stock = np.where(BETA > 1.5, 1, np.where(BETA < 0.8, -1, 0))\n",
    "    BOP=talib.BOP(Open, High, Low, Close)\n",
    "    BOP_trend = np.diff(BOP, prepend=np.nan)\n",
    "    BOP_Crossover = np.where(BOP > 0, 1, np.where(BOP < 0, -1, 0))\n",
    "    MAX=talib.MAX(Close, timeperiod=5)\n",
    "    MEDPRICE=talib.MEDPRICE(High, Low)\n",
    "    MIDPOINT=talib.MIDPOINT(Close, timeperiod=5)\n",
    "    MIDPRICE=talib.MIDPRICE(High, Low, timeperiod=5)\n",
    "    MIN=talib.MIN(Close, timeperiod=5)\n",
    "    ROC=talib.ROC(Close, timeperiod=5)\n",
    "    ROC_trend = np.diff(ROC, prepend=np.nan)\n",
    "    ROC_Crossover = np.where(ROC > 0, 1, np.where(ROC < 0, -1, 0))\n",
    "    TYPPRICE=talib.TYPPRICE(High, Low, Close)\n",
    "    WCLPRICE=talib.WCLPRICE(High, Low, Close)\n",
    "\n",
    "    #bands and moving average\n",
    "    BB_upper, BB_middle, BB_lower =talib.BBANDS(Close, timeperiod=5, nbdevup=1, nbdevdn=1, matype=0)\n",
    "    BB_width = BB_upper - BB_lower / BB_middle\n",
    "    BB_trend = np.diff(BB_middle, prepend = np.nan)\n",
    "    BB_breakout = np.where(Close > BB_upper, 1, np.where(Close < BB_lower, -1, 0))\n",
    "    BB_squeeze = np.where(BB_width < np.convolve(BB_width, np.ones(20) / 20, mode='same'), 1, 0)\n",
    "    SMA=talib.SMA(Close, timeperiod=5)\n",
    "    EMA=talib.EMA(Close, timeperiod=5)\n",
    "    WMA=talib.WMA(Close, timeperiod=5)\n",
    "    TEMA=talib.TEMA(Close, timeperiod=5)\n",
    "    TRIMA=talib.TRIMA(Close, timeperiod=5)\n",
    "    DEMA=talib.DEMA(Close, timeperiod=5)\n",
    "    KAMA=talib.KAMA(Close, timeperiod=5)\n",
    "    MACD, MACD_signal, MACD_hist = talib.MACDEXT(Close, fastperiod=5, slowperiod=10, signalperiod=9, fastmatype=0, slowmatype=0, signalmatype=0)\n",
    "    MACD_Crossover = np.where(MACD > MACD_signal, 1, -1)\n",
    "    MACD_Divergence = np.where((np.diff(Close, prepend=np.nan) > 0) & (MACD_hist < 0), -1, np.where((np.diff(Close, prepend=np.nan) < 0) & (MACD_hist > 0), 1, 0))\n",
    "    MAMA, FAMA = talib.MAMA(Close, fastlimit=0.5, slowlimit=0.05)\n",
    "    MAMA_Crossover = np.where(MAMA > FAMA, 1, -1)\n",
    "    MAMA_Spread = MAMA - FAMA\n",
    "    MAMA_Trend = np.sign(np.diff(MAMA))\n",
    "    T3=talib.T3(Close, timeperiod=5, vfactor=0.7)\n",
    "    TRIX=talib.TRIX(Close, timeperiod=5)\n",
    "\n",
    "    #hilbert transform indicators (cycle indicators)\n",
    "    DCPERIOD=talib.HT_DCPERIOD(Close)\n",
    "    Cycle_change = np.sign(np.diff(DCPERIOD, prepend=np.nan))\n",
    "    DCPHASE=talib.HT_DCPHASE(Close)\n",
    "    PHASE_Crossover = np.where((DCPHASE < -270) & (np.roll(DCPHASE,1) >= -270), 1, np.where((DCPHASE > -90) & (np.roll(DCPHASE,1) <= -90), -1, 0))\n",
    "    PHASE_trend = np.diff(DCPHASE, prepend=DCPHASE[0])\n",
    "    IN_PHASE , QUADRATURE =talib.HT_PHASOR(Close)\n",
    "    PHASE_ANGLE = np.degrees(np.arctan2(QUADRATURE, IN_PHASE))\n",
    "    PHASE_Crossover = np.where((QUADRATURE > IN_PHASE) & (np.roll(QUADRATURE,1) <= np.roll(IN_PHASE,1)), 1,\n",
    "                               np.where((QUADRATURE < IN_PHASE) & (np.roll(QUADRATURE,1) >= np.roll(IN_PHASE,1)), -1, 0))\n",
    "    CYCLE_Strength = np.sqrt(IN_PHASE**2 + QUADRATURE**2)\n",
    "    SINE, LEADSINE = talib.HT_SINE(Close)\n",
    "    SINE_Trend = np.sign(LEADSINE - SINE)\n",
    "    SINE_Crossover = np.where((LEADSINE > SINE) & (np.roll(LEADSINE,1) <= np.roll(SINE,1)), 1, \n",
    "                              np.where((LEADSINE < SINE) & (np.roll(LEADSINE,1) >= np.roll(SINE,1)), -1, 0))\n",
    "    TRENDLINE=talib.HT_TRENDLINE(Close)\n",
    "    TRENDMODE=talib.HT_TRENDMODE(Close)\n",
    "\n",
    "    #statistical indicators\n",
    "    LINEARREG=talib.LINEARREG(Close, timeperiod=14)\n",
    "    LINEARREG_SLOPE=talib.LINEARREG_SLOPE(Close, timeperiod=14)\n",
    "    #CORREL=talib.CORREL(real0, real1, timeperiod=30)\n",
    "    STDDEV=talib.STDDEV(Close, timeperiod=5, nbdev=1)\n",
    "    VAR=talib.VAR(Close, timeperiod=5, nbdev=1)\n",
    "\n",
    "    #candlestick patterns\n",
    "    '''CDLENGULFING=talib.CDLENGULFING(Open, High, Low, Close)\n",
    "    CDLDOJI=talib.CDLDOJI(Open, High, Low, Close)\n",
    "    CDLHAMMER=talib.CDLHAMMER(Open, High, Low, Close)\n",
    "    CDLMORNINGSTAR=talib.CDLMORNINGSTAR(Open, High, Low, Close, penetration=0)\n",
    "    CDL2CROWS=talib.CDL2CROWS(Open, High, Low, Close)\n",
    "    CDL3BLACKCROWS=talib.CDL3BLACKCROWS(Open, High, Low, Close)\n",
    "    CDL3INSIDE=talib.CDL3INSIDE(Open, High, Low, Close)\n",
    "    CDL3LINESTRIKE=talib.CDL3LINESTRIKE(Open, High, Low, Close)\n",
    "    CDL3STARSINSOUTH=talib.CDL3STARSINSOUTH(Open, High, Low, Close)\n",
    "    CDL3WHITESOLDIERS=talib.CDL3WHITESOLDIERS(Open, High, Low, Close)\n",
    "    CDLABANDONEDBABY=talib.CDLABANDONEDBABY(Open, High, Low, Close, penetration=0)\n",
    "    CDLADVANCEBLOCK=talib.CDLADVANCEBLOCK(Open, High, Low, Close)\n",
    "    CDLBELTHOLD=talib.CDLBELTHOLD(Open, High, Low, Close)\n",
    "    CDLBREAKAWAY=talib.CDLBREAKAWAY(Open, High, Low, Close)\n",
    "    CDLCLOSINGMARUBOZU=talib.CDLCLOSINGMARUBOZU(Open, High, Low, Close)\n",
    "    CDLCONCEALBABYSWALL=talib.CDLCONCEALBABYSWALL(Open, High, Low, Close)\n",
    "    CDLCOUNTERATTACK=talib.CDLCOUNTERATTACK(Open, High, Low, Close)\n",
    "    CDLDARKCLOUDCOVER=talib.CDLDARKCLOUDCOVER(Open, High, Low, Close, penetration=0)\n",
    "    CDLDOJISTAR=talib.CDLDOJISTAR(Open, High, Low, Close),\n",
    "    CDLDRAGONFLYDOJI=talib.CDLDRAGONFLYDOJI(Open, High, Low, Close),\n",
    "    CDLEVENINGDOJISTAR=talib.CDLEVENINGDOJISTAR(Open, High, Low, Close, penetration=0),\n",
    "    CDLEVENINGSTAR=talib.CDLEVENINGSTAR(Open, High, Low, Close, penetration=0),\n",
    "    CDLGAPSIDESIDEWHITE=talib.CDLGAPSIDESIDEWHITE(Open, High, Low, Close),\n",
    "    CDLGRAVESTONEDOJI=talib.CDLGRAVESTONEDOJI(Open, High, Low, Close),\n",
    "    CDLHANGINGMAN=talib.CDLHANGINGMAN(Open, High, Low, Close),\n",
    "    CDLHARAMI=talib.CDLHARAMI(Open, High, Low, Close),\n",
    "    CDLHARAMICROSS=talib.CDLHARAMICROSS(Open, High, Low, Close),\n",
    "    CDLHIGHWAVE=talib.CDLHIGHWAVE(Open, High, Low, Close),\n",
    "    CDLHIKKAKE=talib.CDLHIKKAKE(Open, High, Low, Close),\n",
    "    CDLHIKKAKEMOD=talib.CDLHIKKAKEMOD(Open, High, Low, Close),\n",
    "    CDLHOMINGPIGEON=talib.CDLHOMINGPIGEON(Open, High, Low, Close),\n",
    "    CDLIDENTICAL3CROWS=talib.CDLIDENTICAL3CROWS(Open, High, Low, Close),\n",
    "    CDLINNECK=talib.CDLINNECK(Open, High, Low, Close),\n",
    "    CDLINVERTEDHAMMER=talib.CDLINVERTEDHAMMER(Open, High, Low, Close),\n",
    "    CDLKICKING=talib.CDLKICKING(Open, High, Low, Close),\n",
    "    CDLKICKINGBYLENGTH=talib.CDLKICKINGBYLENGTH(Open, High, Low, Close),\n",
    "    CDLLADDERBOTTOM=talib.CDLLADDERBOTTOM(Open, High, Low, Close),\n",
    "    CDLLONGLEGGEDDOJI=talib.CDLLONGLEGGEDDOJI(Open, High, Low, Close),\n",
    "    CDLLONGLINE=talib.CDLLONGLINE(Open, High, Low, Close),\n",
    "    CDLMARUBOZU=talib.CDLMARUBOZU(Open, High, Low, Close),\n",
    "    CDLMATCHINGLOW=talib.CDLMATCHINGLOW(Open, High, Low, Close),\n",
    "    CDLMATHOLD=talib.CDLMATHOLD(Open, High, Low, Close, penetration=0),\n",
    "    CDLMORNINGDOJISTAR=talib.CDLMORNINGDOJISTAR(Open, High, Low, Close, penetration=0),\n",
    "    CDLONNECK=talib.CDLONNECK(Open, High, Low, Close),\n",
    "    CDLPIERCING=talib.CDLPIERCING(Open, High, Low, Close),\n",
    "    CDLRICKSHAWMAN=talib.CDLRICKSHAWMAN(Open, High, Low, Close),\n",
    "    CDLRISEFALL3METHODS=talib.CDLRISEFALL3METHODS(Open, High, Low, Close),\n",
    "    CDLSEPARATINGLINES=talib.CDLSEPARATINGLINES(Open, High, Low, Close),\n",
    "    CDLSHOOTINGSTAR=talib.CDLSHOOTINGSTAR(Open, High, Low, Close),\n",
    "    CDLSHORTLINE=talib.CDLSHORTLINE(Open, High, Low, Close),\n",
    "    CDLSPINNINGTOP=talib.CDLSPINNINGTOP(Open, High, Low, Close),\n",
    "    CDLSTALLEDPATTERN=talib.CDLSTALLEDPATTERN(Open, High, Low, Close),\n",
    "    CDLSTICKSANDWICH=talib.CDLSTICKSANDWICH(Open, High, Low, Close),\n",
    "    CDLTAKURI=talib.CDLTAKURI(Open, High, Low, Close),\n",
    "    CDLTASUKIGAP=talib.CDLTASUKIGAP(Open, High, Low, Close),\n",
    "    CDLTHRUSTING=talib.CDLTHRUSTING(Open, High, Low, Close),\n",
    "    CDLTRISTAR=talib.CDLTRISTAR(Open, High, Low, Close),\n",
    "    CDLUNIQUE3RIVER=talib.CDLUNIQUE3RIVER(Open, High, Low, Close),\n",
    "    CDLUPSIDEGAP2CROWS=talib.CDLUPSIDEGAP2CROWS(Open, High, Low, Close),\n",
    "    CDLXSIDEGAP3METHODS=talib.CDLXSIDEGAP3METHODS(Open, High, Low, Close),'''\n",
    "    \n",
    "    #trend and oscillator indicator\n",
    "    #MACD=talib.MACD(Close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    RSI=talib.RSI(Close, timeperiod=5)\n",
    "    #STOCH=talib.STOCH(High, Low, Close, fastk_period=5, slowk_period=3, slowd_period=3)\n",
    "    CMO=talib.CMO(Close, timeperiod=5)\n",
    "    DX=talib.DX(High, Low, Close, timeperiod=5)\n",
    "    ULTOSC=talib.ULTOSC(High, Low, Close, timeperiod1=5, timeperiod2=10, timeperiod3=15)\n",
    "    PPO=talib.PPO(Close, fastperiod=5, slowperiod=10, matype=0)\n",
    "    \n",
    "    #miscellaneous indicators\n",
    "    MFI=talib.MFI(High, Low, Close, Volume, timeperiod=5)\n",
    "    OBV=talib.OBV(Close, Volume)\n",
    "    CCI=talib.CCI(High, Low, Close, timeperiod=5)\n",
    "    SAR=talib.SAR(High, Low, acceleration=0.02, maximum=0.2)\n",
    "    WILLR=talib.WILLR(High, Low, Close, timeperiod=5)\n",
    "    #MACDFIX=talib.MACDFIX(Close, signalperiod=9)\n",
    "    SAREXT=talib.SAREXT(High, Low, startvalue=0, offsetonreverse=0, accelerationinitlong=0.02,\n",
    "                            accelerationlong=0.02, accelerationmaxlong=0.2, accelerationinitshort=0.02,\n",
    "                            accelerationshort=0.02, accelerationmaxshort=0.2)\n",
    "\n",
    "    #stochastic indicators\n",
    "    #STOCHF=talib.STOCHF(High, Low, Close, fastk_period=5, fastd_period=3, fastd_matype=0)\n",
    "    #STOCHRSI=talib.STOCHRSI(Close, timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)\n",
    "    TSF=talib.TSF(Close, timeperiod=5)\n",
    "    \n",
    "    indicators = {\n",
    "        'AD' : AD.tolist(),\n",
    "        'AD_trend' : AD_trend.tolist(),\n",
    "        'AD_Crossover' : AD_Crossover.tolist(),\n",
    "        'ADOSC' : ADOSC.tolist(),\n",
    "        'ADOSC_trend' : ADOSC_trend.tolist(),\n",
    "        'ADOSC_Crossover' : ADOSC_Crossover.tolist(),\n",
    "        'ADX' : ADX.tolist(),\n",
    "        'ADX_trend' : ADX_trend.tolist(),\n",
    "        'PLUS_DI' : PLUS_DI.tolist(),\n",
    "        'MINUS_DI' : MINUS_DI.tolist(),\n",
    "        #'DI_Crossover' : list(DI_Crossover),\n",
    "        'ADXR' : ADXR.tolist(),\n",
    "        'ADXR_trend' : ADXR_trend.tolist(),\n",
    "        'MINUS_DM' : MINUS_DM.tolist(),\n",
    "        'PLUS_DM' : PLUS_DM.tolist(),\n",
    "        'DM_Crossover' : DM_Crossover.tolist(),\n",
    "        'APO' : APO.tolist(),\n",
    "        'APO_trend' : APO_trend.tolist(),\n",
    "        'APO_Crossover' : APO_Crossover.tolist(),\n",
    "        'AROON_UP' : AROON_UP.tolist(),\n",
    "        'AROON_DOWN' : AROON_DOWN.tolist(),\n",
    "        'AROONOSC' : AROONOSC.tolist(),\n",
    "        'AROON_Crossover' : AROON_Crossover.tolist(),\n",
    "        'MOM' : MOM.tolist(),\n",
    "        'MOM_trend' : MOM_trend.tolist(),\n",
    "        'MOM_Crossover' : list(MOM_Crossover),\n",
    "        'ATR' : ATR.tolist(),\n",
    "        'ATR_trend' : ATR_trend.tolist(),\n",
    "        'ATR_breakout' : ATR_breakout.tolist(),\n",
    "        'NATR' : NATR.tolist(),\n",
    "        'NATR_trend' : NATR_trend.tolist(),\n",
    "        'High_Volatility' : High_Volatility.tolist(),\n",
    "        'TRANGE' : TRANGE.tolist(),\n",
    "        'TRANGE_trend' : TRANGE_trend.tolist(),\n",
    "        'Volatility_Spike' : Volatility_Spike.tolist(),\n",
    "        'AVGPRICE' : AVGPRICE.tolist(),\n",
    "        'Price_Deviation' : Price_Deviation.tolist(),\n",
    "        'AVGPRICE_trend' : AVGPRICE_trend.tolist(),\n",
    "        'AVGPRICE_Crossover' : AVGPRICE_Crossover.tolist(),\n",
    "        'BETA' : BETA.tolist(),\n",
    "        'BETA_trend' : BETA_trend.tolist(),\n",
    "        'High_Beta_Stock' : High_Beta_Stock.tolist(),\n",
    "        'BOP' : BOP.tolist(),\n",
    "        'BOP_trend' : BOP_trend.tolist(),\n",
    "        'BOP_Crossover' : BOP_Crossover.tolist(),\n",
    "        'MAX' : MAX.tolist(),\n",
    "        'MEDPRICE' : MEDPRICE.tolist(),\n",
    "        'MIDPOINT' : MIDPOINT.tolist(),\n",
    "        'MIDPRICE' : MIDPRICE.tolist(),\n",
    "        'MIN' : MIN.tolist(),\n",
    "        'ROC' : ROC.tolist(),\n",
    "        'ROC_trend' : ROC_trend.tolist(),\n",
    "        'ROC_Crossover' : ROC_Crossover.tolist(),\n",
    "        'TYPPRICE' : TYPPRICE.tolist(),\n",
    "        'WCLPRICE' : WCLPRICE.tolist(),\n",
    "        'BB_upper' : BB_upper.tolist(),\n",
    "        'BB_middle' : BB_middle.tolist(),\n",
    "        'BB_lower' : BB_lower.tolist(),\n",
    "        'BB_width' : BB_width.tolist(),\n",
    "        'BB_trend' : BB_trend.tolist(),\n",
    "        'BB_breakout' : BB_breakout.tolist(),\n",
    "        'BB_squeeze' : BB_squeeze.tolist(),\n",
    "        'SMA' : SMA.tolist(),\n",
    "        'EMA' : EMA.tolist(),\n",
    "        'WMA' : WMA.tolist(),\n",
    "        'TEMA' : TEMA.tolist(),\n",
    "        'TRIMA' : TRIMA.tolist(),\n",
    "        'DEMA' : DEMA.tolist(),\n",
    "        'KAMA' : KAMA.tolist(),\n",
    "        'MACD' : MACD.tolist(), \n",
    "        'MACD_signal' : MACD_signal.tolist(), \n",
    "        'macd-hist' : MACD_hist.tolist(),\n",
    "        'MACD_Crossover' : MACD_Crossover.tolist(),\n",
    "        'MACD_Divergence' : MACD_Divergence.tolist(),\n",
    "        'MAMA' : MAMA.tolist(), \n",
    "        'FAMA' : FAMA.tolist(),\n",
    "        'MAMA_Crossover' : MAMA_Crossover.tolist(), \n",
    "        'MAMA_Spread' : MAMA_Spread.tolist(),\n",
    "        'MAMA_Trend' : MAMA_Trend.tolist(),\n",
    "        'T3' : T3.tolist(),\n",
    "        'TRIX' : TRIX.tolist(),\n",
    "        'DCPERIOD' : DCPERIOD.tolist(),\n",
    "        'Cycle_change' : Cycle_change.tolist(),\n",
    "        'DCPHASE' : DCPHASE.tolist(),\n",
    "        'PHASE_Crossover' : PHASE_Crossover.tolist(),\n",
    "        'PHASE_trend' : PHASE_trend.tolist(),\n",
    "        'IN_PHASE' : IN_PHASE.tolist(), \n",
    "        'QUADRATURE' : QUADRATURE.tolist(),\n",
    "        'PHASE_ANGLE' : PHASE_ANGLE.tolist(),\n",
    "        'PHASE_Crossover' : PHASE_Crossover.tolist(),\n",
    "        'CYCLE_Strength' : CYCLE_Strength.tolist(),\n",
    "        'SINE' : SINE.tolist(),\n",
    "        'LEADSINE' : LEADSINE.tolist(),\n",
    "        'SINE_Trend' : SINE_Trend.tolist(),\n",
    "        'SINE_Crossover' : SINE_Crossover.tolist(),\n",
    "        'TRENDLINE' : TRENDLINE.tolist(),\n",
    "        'TRENDMODE' : TRENDMODE.tolist(),\n",
    "        'LINEARREG' : LINEARREG.tolist(),\n",
    "        'LINEARREG_SLOPE' : LINEARREG_SLOPE.tolist(),\n",
    "        'STDDEV' : STDDEV.tolist(),\n",
    "        'VAR' : VAR.tolist(),\n",
    "        'RSI' : RSI.tolist(),\n",
    "        'CMO' : CMO.tolist(),\n",
    "        'DX' : DX.tolist(),\n",
    "        'ULTOSC' : ULTOSC.tolist(),\n",
    "        'PPO' : PPO.tolist(),\n",
    "        'MFI' : MFI.tolist(),\n",
    "        'OBV' : OBV.tolist(),\n",
    "        'CCI' : CCI.tolist(),\n",
    "        'SAR' : SAR.tolist(),\n",
    "        'WILLR' : WILLR.tolist(),\n",
    "        'SAREXT' : SAREXT.tolist(),\n",
    "        'TSF' : TSF.tolist()\n",
    "    }\n",
    "\n",
    "    for key in indicators.keys():\n",
    "        indicators[key] = prepend_nan(indicators[key], len(df))\n",
    "\n",
    "    indicators_df = pd.DataFrame(indicators)    \n",
    "\n",
    "    df = pd.concat([df, indicators_df], axis=1)   \n",
    "    \n",
    "    df.to_csv(\"data_with_indicators/\" + ticker_name + \"_indicators.csv\", index=False),\n",
    "    return\n",
    "\n",
    "def remove_unwanted_features(ticker):\n",
    "    df = pd.read_csv(\"data_with_indicators/\" + ticker + \"_indicators.csv\")\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique() == 1:\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    df.to_csv(\"data_with_indicators/\" + ticker + \"_indicators.csv\")\n",
    "    return\n",
    "\n",
    "def prepend_nan(indicator, target_length):\n",
    "    if len(indicator) < target_length:\n",
    "        padding = np.full(target_length - len(indicator), np.nan)\n",
    "        return np.concatenate((padding, indicator))\n",
    "    return indicator\n",
    "\n",
    "input_csv = \"nse_symbols.csv\"\n",
    "symbols_df = pd.read_csv(input_csv)\n",
    "symbols = symbols_df['Symbol'].tolist()\n",
    "\n",
    "for symbol in symbols:\n",
    "    print(f\"Processing: {symbol}\")\n",
    "    get_indicators(symbol)\n",
    "    remove_unwanted_features(symbol)\n",
    "\n",
    "print(\"Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1944ed66-9d4a-495e-b418-bcf789b2b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make 2 targets classifications and regression... done\n",
    "#make features as per basis of manual trading.... Done\n",
    "#normalize all indicators... done\n",
    "#data sanity checks.... done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab030e-ae97-432e-ace9-23cc0dece702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding targets\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def add_targets(\n",
    "    ticker: str,\n",
    "    in_folder: str = \"data_with_indicators\",\n",
    "    out_folder: str = \"data_with_targets\"\n",
    ") -> None:\n",
    "    df = pd.read_csv(f\"{in_folder}/{ticker}_indicators.csv\")\n",
    "\n",
    "    future_high = df[\"High\"].shift(-6)\n",
    "    df[\"Target2\"] = ((future_high - df[\"Close\"]) / df[\"Close\"])\n",
    "    df.iloc[-6:, df.columns.get_loc(\"Target2\")] = 0\n",
    "\n",
    "    five_day_high = (\n",
    "        df[\"High\"]\n",
    "        .rolling(window=5, min_periods=1)\n",
    "        .max()\n",
    "        .shift(-5)\n",
    "    )\n",
    "    df[\"Target1\"] = (five_day_high >= df[\"Close\"] * 1.04).astype(int)\n",
    "    df.iloc[-5:, df.columns.get_loc(\"Target1\")] = 0\n",
    "\n",
    "    Path(out_folder).mkdir(exist_ok=True)\n",
    "    df.to_csv(f\"{out_folder}/{ticker}_indicators.csv\", index=False)\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    symbols = pd.read_csv(\"nse_symbols.csv\")[\"Symbol\"]\n",
    "    for sym in symbols:\n",
    "        print(f\"Processing: {sym}\")\n",
    "        add_targets(sym)\n",
    "    print(\"Completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27521bd8-868f-487e-881c-762dc77ec8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#Normalizing all indicators\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale(ticker):\n",
    "    df = pd.read_csv(\"data_with_indicators/\" + ticker + \"_indicators.csv\")\n",
    "    \n",
    "    columns_to_scale = df.columns[(df.columns != 'Date') & ~df.isin([0, 1, -1]).all()]\n",
    "    scaler = StandardScaler()\n",
    "    df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "    output_path = f\"scaled_data/{ticker}_scaled.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "input_csv = \"nse_symbols.csv\"\n",
    "symbols_df = pd.read_csv(input_csv)\n",
    "symbols = symbols_df['Symbol'].tolist()\n",
    "\n",
    "for symbol in symbols:\n",
    "    print(f\"Processing: {symbol}\")\n",
    "    scale(symbol)\n",
    "\n",
    "print(\"Completed!\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218aae9b-9e96-413f-8e88-ae270cdcd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test split\n",
    "# feature elimination RFE library\n",
    "# boruta package\n",
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87cb58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Load and concatenate all stock indicator CSVs\n",
    "all_data = []\n",
    "for path in glob.glob(\"data_with_indicators/*.csv\"):\n",
    "    ticker = path.split(\"/\")[-1].split(\"_\")[0]\n",
    "    df = pd.read_csv(path)\n",
    "    df['Ticker'] = ticker\n",
    "    all_data.append(df)\n",
    "\n",
    "df_all = pd.concat(all_data).dropna().sort_values([\"Date\", \"Ticker\"])\n",
    "\n",
    "# Define features and targets\n",
    "exclude_cols = [\"Date\", \"Ticker\", \"Target1\", \"Target2\"]\n",
    "feature_cols = [col for col in df_all.columns if col not in exclude_cols]\n",
    "X = df_all[feature_cols]\n",
    "y = df_all[\"Target1\"]\n",
    "\n",
    "# Train/test split based on time (to avoid leakage)\n",
    "df_all[\"Date\"] = pd.to_datetime(df_all[\"Date\"])\n",
    "cutoff_date = df_all[\"Date\"].quantile(0.8)\n",
    "train_idx = df_all[\"Date\"] <= cutoff_date\n",
    "test_idx = df_all[\"Date\"] > cutoff_date\n",
    "\n",
    "X_train = X[train_idx]\n",
    "X_test = X[test_idx]\n",
    "y_train = y[train_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "# Normalize using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "y_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_proba))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Classifier and Regressor\n",
    "import os, warnings, joblib, glob, math   \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, roc_curve,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt                   \n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_DIR   = Path(\"data_with_targets\")\n",
    "LOOKBACK   = 20\n",
    "TEST_FRAC  = 0.15\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS     = 30\n",
    "PATIENCE   = 5\n",
    "THRESH     = 0.50          \n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"plots\",  exist_ok=True)          \n",
    "\n",
    "# helper: build feature selector pipeline\n",
    "def build_selector():\n",
    "    return Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\",  StandardScaler()),\n",
    "        (\"rfecv\",   RFECV(\n",
    "            estimator  = LogisticRegression(max_iter=1000),\n",
    "            cv         = StratifiedKFold(n_splits=5),\n",
    "            scoring    = \"accuracy\",\n",
    "            step       = 1,\n",
    "            n_jobs     = -1,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "# helper: roll 2-D → 3-D sequences + aligned targets\n",
    "def make_seq(X, y, L):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(L, len(X)):\n",
    "        Xs.append(X[i-L:i])\n",
    "        ys.append(y[i])\n",
    "    return np.array(Xs, dtype=np.float32), np.array(ys)\n",
    "\n",
    "\n",
    "for csv_path in sorted(DATA_DIR.glob(\"*_indicators.csv\")):\n",
    "    ticker = csv_path.stem.split(\"_\")[0]\n",
    "    print(f\"⏳  {ticker}: feature selection...\", flush=True)\n",
    "    df = pd.read_csv(csv_path).sort_values(\"Date\").reset_index(drop=True)\n",
    "    df.drop(columns=[\"Unnamed: 0\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c not in [\"Date\", \"Target1\", \"Target2\"]]\n",
    "    X_raw, y_cls_raw, y_reg_raw = df[feature_cols], df[\"Target1\"].astype(int), df[\"Target2\"]\n",
    "\n",
    "    if y_cls_raw.sum() == 0:         \n",
    "        print(f\"{ticker:<10} skipped (no +4 % events)\")\n",
    "        continue\n",
    "\n",
    "    cutoff = int(len(df) * (1 - TEST_FRAC))\n",
    "    pipe   = build_selector()\n",
    "    pipe.fit(X_raw.iloc[:cutoff], y_cls_raw.iloc[:cutoff])\n",
    "    X_prep = pipe.transform(X_raw)\n",
    "\n",
    "    X_seq, y_cls_seq = make_seq(X_prep, y_cls_raw.values, LOOKBACK)\n",
    "    _,     y_reg_seq = make_seq(X_prep, y_reg_raw.values, LOOKBACK)\n",
    "\n",
    "    split = int(len(X_seq) * (1 - TEST_FRAC))\n",
    "    X_tr, X_te          = X_seq[:split],       X_seq[split:]\n",
    "    y_cls_tr, y_cls_te  = y_cls_seq[:split],   y_cls_seq[split:]\n",
    "    y_reg_tr, y_reg_te  = y_reg_seq[:split],   y_reg_seq[split:]\n",
    "\n",
    "    clf = models.Sequential([\n",
    "        layers.Input(shape=(LOOKBACK, X_tr.shape[-1])),\n",
    "        layers.LSTM(64, return_sequences=True),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.LSTM(32),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    clf.compile(optimizer=\"adam\",\n",
    "                loss=\"binary_crossentropy\",\n",
    "                metrics=[\"AUC\"])\n",
    "\n",
    "    clf.fit(\n",
    "        X_tr, y_cls_tr,\n",
    "        validation_split=0.1,\n",
    "        epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "        callbacks=[EarlyStopping(\"val_auc\", patience=PATIENCE,\n",
    "                                 mode=\"max\", restore_best_weights=True)],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    reg = models.Sequential([\n",
    "        layers.Input(shape=(LOOKBACK, X_tr.shape[-1])),\n",
    "        layers.LSTM(64, return_sequences=True),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.LSTM(32),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    reg.compile(optimizer=\"adam\", loss=\"mae\")\n",
    "\n",
    "    reg.fit(\n",
    "        X_tr, y_reg_tr,\n",
    "        validation_split=0.1,\n",
    "        epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "        callbacks=[EarlyStopping(\"val_loss\", patience=PATIENCE,\n",
    "                                 restore_best_weights=True)],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    prob_up = clf.predict(X_te, verbose=0).ravel()\n",
    "    reg_out = reg.predict(X_te, verbose=0).ravel()\n",
    "    y_pred_cls = (prob_up >= THRESH).astype(int)\n",
    "\n",
    "    acc  = accuracy_score(y_cls_te, y_pred_cls)\n",
    "    prec = precision_score(y_cls_te, y_pred_cls, zero_division=0)\n",
    "    rec  = recall_score(y_cls_te, y_pred_cls, zero_division=0)\n",
    "    f1   = f1_score(y_cls_te, y_pred_cls, zero_division=0)\n",
    "    auc  = roc_auc_score(y_cls_te, prob_up)\n",
    "\n",
    "    print(f\"\\n📊  {ticker} — classifier metrics (test)\")\n",
    "    print(f\"accuracy   : {acc: .3f}\")\n",
    "    print(f\"precision  : {prec:.3f}\")\n",
    "    print(f\"recall     : {rec: .3f}\")\n",
    "    print(f\"F1-score   : {f1 : .3f}\")\n",
    "    print(f\"AUC        : {auc:.3f}\")\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_cls_te, prob_up)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"AUC={auc:.2f}\")\n",
    "    plt.plot([0,1], [0,1], \"--\", color=\"gray\")\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"{ticker} ROC Curve\")\n",
    "    plt.legend()\n",
    "    roc_path = f\"plots/{ticker}_roc.png\"\n",
    "    plt.savefig(roc_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"ROC curve  → {roc_path}\")\n",
    "\n",
    "    mae  = mean_absolute_error(y_reg_te, reg_out)\n",
    "    rmse = math.sqrt(mean_squared_error(y_reg_te, reg_out))\n",
    "    r2   = r2_score(y_reg_te, reg_out)\n",
    "\n",
    "    print(f\"\\n📊  {ticker} — regressor metrics (test)\")\n",
    "    print(f\"MAE  (ratio)      : {mae: .4f}\")\n",
    "    print(f\"RMSE (ratio)      : {rmse:.4f}\")\n",
    "    print(f\"R²                : {r2  : .3f}\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(y_reg_te * 100, reg_out * 100, alpha=0.3)\n",
    "    plt.xlabel(\"Actual % move\"); plt.ylabel(\"Predicted % move\")\n",
    "    plt.title(f\"{ticker} Predicted vs Actual (%)\")\n",
    "    plt.axline((0,0), slope=1, color=\"gray\", linestyle=\"--\")\n",
    "    pv_path = f\"plots/{ticker}_pred_vs_actual.png\"\n",
    "    plt.savefig(pv_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print(f\"Scatter     → {pv_path}\")\n",
    "\n",
    "    test_dates = df[\"Date\"].iloc[LOOKBACK + split:].reset_index(drop=True)\n",
    "    mask = prob_up >= THRESH\n",
    "    if mask.sum() == 0:\n",
    "        print(f\"{ticker:<10}  — no ≥{THRESH:.0%} up-prob signals in test set\\n\")\n",
    "        continue\n",
    "\n",
    "    signals = pd.DataFrame({\n",
    "        \"Date\"            : test_dates[mask],\n",
    "        \"P(up≥4%)\"        : prob_up[mask].round(3),\n",
    "        \"Pred_%Move(%)\"   : (reg_out[mask] * 100).round(2),\n",
    "        \"Actual_%Move(%)\" : (y_reg_te[mask] * 100).round(2),\n",
    "        \"Actual≥4%\"       : (y_reg_te[mask] >= 0.04).astype(int)\n",
    "    })\n",
    "\n",
    "    print(f\"\\n{ticker} — Signals (≥{THRESH:.0%} prob) on last {TEST_FRAC:.0%} of data\")\n",
    "    print(signals.to_string(index=False))\n",
    "    print(\"-\" * 70, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafc54d7-515d-48be-b291-e99eba2a7d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert to percentage values for readability\n",
    "actual_pct   = y_reg_te * 100\n",
    "predicted_pct = reg_out * 100\n",
    "\n",
    "# Convert to percentage values for readability\n",
    "actual_pct   = y_reg_te * 100\n",
    "predicted_pct = reg_out * 100\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(actual_pct, predicted_pct, alpha=0.5, edgecolor='k')\n",
    "plt.plot([actual_pct.min(), actual_pct.max()],\n",
    "         [actual_pct.min(), actual_pct.max()],\n",
    "         color='red', linestyle='--', label='Ideal Prediction (y = x)')\n",
    "\n",
    "plt.title(\"LSTM Regression: Predicted vs Actual % Movement\")\n",
    "plt.xlabel(\"Actual % Movement\")\n",
    "plt.ylabel(\"Predicted % Movement\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(actual_pct, predicted_pct, alpha=0.5, edgecolor='k')\n",
    "plt.plot([actual_pct.min(), actual_pct.max()],\n",
    "         [actual_pct.min(), actual_pct.max()],\n",
    "         color='red', linestyle='--', label='Ideal Prediction (y = x)')\n",
    "\n",
    "plt.title(\"LSTM Regression: Predicted vs Actual % Movement\")\n",
    "plt.xlabel(\"Actual % Movement\")\n",
    "plt.ylabel(\"Predicted % Movement\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea2e42-f516-43e1-aedf-53f1bbf416b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# ------------------------------------------------------------\n",
    "# LSTM CLASSIFIER (Target1) & LSTM REGRESSOR (Target2)\n",
    "# ------------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "X_all = np.array(X_all)\n",
    "y_cls_all = np.array(y_cls_all)\n",
    "y_reg_all = np.array(y_reg_all)\n",
    "\n",
    "# Chronological split (keep ordering)\n",
    "split_idx = int(X_all.shape[0] * 0.8)\n",
    "X_train, X_val = X_all[:split_idx], X_all[split_idx:]\n",
    "y_cls_train, y_cls_val = y_cls_all[:split_idx], y_cls_all[split_idx:]\n",
    "y_reg_train, y_reg_val = y_reg_all[:split_idx], y_reg_all[split_idx:]\n",
    "\n",
    "# ---- Classifier ----\n",
    "cls_model = models.Sequential([\n",
    "    layers.Input(shape=(X_all.shape[1], X_all.shape[2])),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(32),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "cls_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "cls_model.fit(\n",
    "    X_train, y_cls_train,\n",
    "    validation_data=(X_val, y_cls_val),\n",
    "    epochs=30,\n",
    "    batch_size=256,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_auc', mode='max', patience=5, restore_best_weights=True)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate classifier\n",
    "cls_auc = cls_model.evaluate(X_val, y_cls_val, verbose=0)[1]\n",
    "print(f'Classifier ROC-AUC: {cls_auc:.4f}')\n",
    "\n",
    "# ---- Regressor ----\n",
    "reg_model = models.Sequential([\n",
    "    layers.Input(shape=(X_all.shape[1], X_all.shape[2])),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(32),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1)   # linear activation for regression\n",
    "])\n",
    "reg_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "reg_model.fit(\n",
    "    X_train, y_reg_train,\n",
    "    validation_data=(X_val, y_reg_val),\n",
    "    epochs=30,\n",
    "    batch_size=256,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_mae', mode='min', patience=5, restore_best_weights=True)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate regressor\n",
    "reg_loss, reg_mae = reg_model.evaluate(X_val, y_reg_val, verbose=0)\n",
    "print(f'Regressor MAE: {reg_mae:.4f}')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
